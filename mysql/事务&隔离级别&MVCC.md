# ACID

必须满足4个条件:

原子性（Autmic）：一次事务中所有的指令，要么都执行，要么都不执行、

一致性（Consistency）：事务的操作应该使数据库从一个一致状态转变倒另一个一致得状态！

持久性（Durability）：一个成功执行得事务对数据库得作用是持久得，即使数据库应故障出错，也应该能够恢复！

隔离性（Isolation）：请求是并发的，多个并发执行的事务相互之间也要隔离的

以上4条都满足，即：事务！！！
>其实满足 ACD 3条就可以是事务了，第4条，是在事务并发时候，考虑的情况

# 事务隔离级别（Isolation）

#### 概念

从 ACID 原则看：如果多个事务并发执行，应象各个事务独立执行一样！
但事务本就是并发使用，过程中会出现：一个事务读取A数据，另一个事务修改A数据

具体一点，程序员操作数据就4种情况：CURD。并行操作时，就会出现错误的情况
>并没有太完美的解决办法，只能看倾向哪种策略，同时加锁来避免这种情况。


事务的隔离策略会带出3个问题：

|       |           |                       | 针对          |
| :---- | :-------- | :-------------------- | ----------- |
| 脏读    | 读取 未提交的数据 | A事务读取了B修改的值，但是B回滚了    | update，某条数据 |
| 幻读    | 读取 已提交的数据 | 两次 select count 的值不一样 | insert，增加数据 |
| 不可重复读 | 读取 已提交的数据 | 两次 select 的字段值不一样     | update，某条数据 |

#### 脏读


基本上没什么隔离，只要某个事务改了数据，另外一个事务立刻就能读到修改后的值。如：


数据：X=1

A和B 两个事务同时执行，如下：

事务 A 把 X 改成了2
事务 B 读取X=2
此时 B 回退了，并未提交事务。也就是：虽然修改了X=2，但回滚后，X=1

那么事务A读取的 X=2，  就是脏数据。
因为A已经回滚了，X=2是错的，真实的是：X=1

#### 幻读

在一个事务中，两次查询的结果不一致(针对的insert操作)

一个事务先根据某些条件查询出一些记录，如：count(id) = 10
之后另一个事务向表中插入了符合这些条件的记录，原先的事务再次按照该条件查询时，能把另一个事务插入的记录也读出来。count(id) = 11


A 读取  年龄 > 10 的有2条
B 新插入了一条数据，此时：年龄 > 10 的有3条了
A 再读取 年龄 > 10 的有3条了？ 两次 读的结果不一样了

#### 不可重复读

只能读取已提交的数据
其他事务每次，对该数据进行一次修改并提交后，其它事务都能查询得到最新值。
针对 UPDATE


从这3个问题来看，SQL 标准提出了四种隔离级别来规避这些现象，隔离级别越高，性能效率就越低，这四个隔离级别如下：

| **事务隔离级别**             | **脏读** | **不可重复读** | **幻读** |
| ---------------------- | ------ | --------- | ------ |
| 读未提交（READ UNCOMMITTED） | √      | √         | √      |
| 读已提交（READ COMMITTED）   | ×      | √         | √      |
| 可重复读（REPEATABLE READ）  | ×      | ×         | √      |
| 串行化（SERIALIZABLE）      | ×      | ×         | ×      |

安全性：
Serializable > 可重读 -> 读已提交  -> 读未提交 

性能：
读未提交 -> 读已提交 -> 可重读 -> Serializable



#### Read Uncommitted

读未提交 的数据，脏读、幻读、不可重复读都会出现

>基本上不会使用这种隔离级别。读取脏数据，挺可怕的

#### Read Committed

读取已提交的数据。一个事务的更新操作结果只有在该事务提交之后，另一个事务才可以的读取到同一笔数据更新后的结果。可避免脏读
>大部分数据库采用的默认隔离级别

缺点：会出现 不可重复读 幻读
问题：在一个事务中,两次查询的结果不一致(针对的update操作)

select时不添加读锁，就会发生不可重复读问题。

#### Repeatable Read（可重读）

mySql 的默认事务隔离级别，理论上，重读会看到同样的数据行，不过，这会导致另一个棘手的问题：幻读 （Phantom Read）。所以，得加琐，就是支持重读。

可避免脏读，可避免不可重复读，但会出现幻读

指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的

#### 4种隔离级别如何解决3个问题

读已提交：借用一个 undo.log 文件，修改数据的时候并不是真实的修改DB里的数据，而是把修改的值先存到 undo.log 文件中。等最后 commit 的时候，再真实修改

可重读：借用一个 undo.log 文件，修改数据的时候并不是真实的修改DB里的数据，而是把修改的值先存到 undo.log 文件中。并且，每次修改都会记录一下，也就是某个值会有一个版本记录列表。

#### Serializable

这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。



# 事务的使用场景


- 一个接口中，有多个 insert 或 update 或 delete 
- A 转账 B 50块，update set price = price - 50 ,update set price = price +50
- 订单付款成功，更新状态订单，增加用户购买的物品记录


# MVCC

Multi-Version Concurrency Control：多版本并发控制，相对的就是基于锁的并发控制

读操作：快照读、当前读

快照读：读取的是可见的版本，加的共享锁。如select xxx (for update 除外)

当前读：读取最新版本，会加排它锁。 update delete insert

当前读 例子，update：

1 MYSQL 根据 where -> innodb -> 找到满足条件的数据记录 ->返回 mysql 记录，并加锁

2 MYSQL 发送更新数据 -> innodb- > 更新完成 解锁 -> 返回mysql

update 、delete差不多，insert操作可能会触发Unique Key的冲突检查，也会进行一个当前读

所以，一个MYSQL用户你禁了select操作，update 一样没权限




```c
SET AUTOCOMMIT=0//设置为不自动提交，因为MYSQL默认立即执行

BEGIN

ROOLBACK

COMMIT
```



# undo/redo

事务执行期间做出更改，先把数据存到 undo 中，再修改数据。如果 rollback，就根据 undo 的日志反向修改之前修改的数据。
所以 undo 日志保存的是旧数据，或者说是：之前的正确数据(已提前)，而磁盘被修改的是新数据，是未提交的

undo 流程：

1. 事务 A：set a = 1
2. DB:
   1. 将 A 的旧值(当前内存中的数据值)，写到 undo buffer 中
   2. 更新内存数据 set a = 1
   3. 将 undo 数据持久化到磁盘中
   4. 将内存数据 a=1 持久化到硬盘中
3. 事务 A：set a = 2
4. DB :
   1. 将 A 的旧值(当前内存中的数据值)，写到 undo buffer 中
   2. 更新内存数据 set a = 2
   3. 将 undo 数据持久化到磁盘中
   4. 将内存数据 a=2 持久化到硬盘中
5. 最终提交

其实就是两份(未提交与已提交)数据的处理，分别存于 4 个\(内存\+文件中\)容器中。一但出错，就用 undo 文件恢复一下就行。

redo：记录修改之后的数据(最新数据)

undo + redo 流程：

1. 事务 A：set a = 1
2. DB:
   1. 将 A 的旧值(当前内存中的数据值)，写到 undo buffer 中
   2. 更新内存数据 set a = 1
   3. 将 A 的新值写到 redo buffer 中
   4. 将 undo 数据持久化到磁盘中
   5. 将 redo 数据持久化到磁盘中
3. 事务 A：set a = 2
4. DB :
   1. 将 A 的旧值\(当前内存中的数据值\)，写到 undo buffer 中
   2. 更新内存数据 set a = 2
   3. 将 A 的新值写到 redo buffer 中
   4. 将 undo 数据持久化到磁盘中
   5. 将 redo 数据持久化到磁盘中
5. DB:
   1. 定期异步，将数据持久化到磁盘中
6. 最终提交

undo:可以恢复 未提交 的修改，因为它保存的就是旧数据
redo:可以恢复 已提交 的数据，因为它保存的就是最新的数据。就算定期异步同步数据未落盘，也可以从 redo 中恢复

这两种方式好像没啥太大区别：数据的持久化也没有省掉，虽然是异常步吧，性能高一点，但还是多了一步 redo 的 IO。

区别：redo 是顺序写，数据是随机写

undo 是不是顺序写？它居然跟 redo 是一个日志文件，有点夸张呢。那也意味着：undo redo 都是顺序写，且一次 IO 就够

redo 持久化的触发机制：buffer 满了，或事务提前。

这里就会有一个问题：redo 日志可能记录未提交的数据，在 buffer 满了后，会触发持久化，而正好在此时用户执行回滚，而 MYSQL 挂了。好像是 MYSQL 会根据 UNDO 来做恢复，就是有点慢




查看当前会话隔离级别:select @@tx_isolation;

查看系统当前隔离级别:select @@global.tx_isolation;

设置当前会话隔离级别:set session transaction isolation level repeatable read;

设置系统当前隔离级别:set global transaction isolation level repeatable read;

低级别的隔离级一般支持更高的并发处理，并拥有更低的系统开销。