
# 基础

在C/C++中内存分为5个区：栈、堆、全局/静态存储区、常量存储区、代码区。
静态分配：全局/静态存储区、常量存储区、代码区。编译时即确定
动态分配：栈、堆，运行时分配

栈：编译器管理，大体上已经确定了（虽然是动态）
堆：程序员分配


# mmu

Memory Management Unit

正常CPU执行代码，是读取内存的物理地址。

1. 当同时启动多个程序，内存只有10M，而多个程序需要12M
2. 物理内存地址，任何进程都可以访问，如果A进程访问了B进程的内存地址，会出问题
3. 多个进程，可以访问同一块物理地址

实际就是：内存虚拟地址 与 物理地址  映射。

由之前：直接访问物理内存地址，改成，中间加了一个层虚拟地址。
虚拟地址转换成物理地址就是MMU

>小结：我们日常说的内存操作，实际并不是直接操作物理内存，都是操作的虚拟内存。


# 内存池


- 进程启动后，创建一个控制器，向 OS 申请一大块内存
- 当程序想要申请内存的时候，不直接使用 malloc ，而向上面的控制器申请
- 释放也是同理，由控制器接管内存控制

malloc：函数相当于向操作系统“批发”了一块较大的内存空间，然后“零售”给程序用。当全部“售完”或程序有更大的内存需求时，再根据实际需求向操作系统“进货”。

malloc的实现方式有很多种，一般不同编译器平台用的都是不同的。比如windows的vs系列用的微软自己写的一套，linux gcc用的是glibc中的ptmalloc。


为什么使用内存池？
- 内存复用最大化
- 减少碎片化
- 提高ID速度

缺点：代码复杂化

# 分配方法


#### 线性分配器

Sequential Allocator，Bump Allocator
只需要一个指针，指向堆的首地址，分配时，就移动该指针

优点：简单，快速
缺点：就一个指针，无法重用，不好做GC

#### FreeList 

空闲链表。把堆上的内存块(未使用的)，用链表结构串起来。当程序员申请内存时，遍历这个(内存空闲)链表，找到大小合适的内存，分配出去。对已分配的内存块用 bitmap 进行标记。
>因为是链表结构，每次获取时间O(n)


具体分配的方式：

- 首次适应（First-Fit）— 从链表头开始遍历，选择第一个大小大于申请内存的内存块；
- 循环首次适应（Next-Fit）— 从上次遍历的结束位置开始遍历，选择第一个大小大于申请内存的内存块；
- 最优适应（Best-Fit）— 从链表头遍历整个链表，选择最合适的内存块；
- 隔离适应（Segregated-Fit）— 将内存分割成多个链表，每个链表中的内存块大小相同，申请内存时先找到满足条件的链表，再从链表中选择合适的内存块；


#### 定长分配

每次申请的内存大小是固定的，如：定义内存块是4KB，此时你申请小于4KB的内存，都会统一给分配一个4KB的内存块


优点：固定大小后，申请者也清楚，哪些申请是要走此控制器，更加有效率
缺点：内存碎片，不可能每次都是申请4KB,比如，申请3.5KB,就浪费了0,5


#### 哈希映射的空闲链表池

和上面差不多，但是加大粒度，比如：
再增加出 16KB 32KB 的控制器，同时，再增加hash定位控制器

也就是增加了N个控制器

缺点：控制器变多后，本身就占用更多的内存了

#### 小结

线性分配基本不可能用，问题太大。freeList只会使用| 隔离适应| 这种方法。同时结果 定长分配 、哈希映射的快速寻找等等等吧。


这几种分配方法，更像是基础方法，实际现在的语言都是结合4种方法，优劣结合，最终形成一种相对平衡的分配方法。

感觉整体的方向就是：内存被划分成固定大小的块，以多个链表进行组织结构。


# TCMalloc



#### page

与 MMU 分配一样，大小为4KB。4 x 1024 / 8 = 4096字节

再以16字节为单位，划分出256个单元（4 x 1024 / 16 ）
每个单元的，前8个字节为指针，指向下下 单元。
>注：一但内存被分配出去，此指针可以删除，并不占用内存空间


#### span

由若干的 page 组成

```
start
length
```



看不下去了，太难了


# GOlang

golang  使用的是 TCMalloc 模式，具体的我没太看懂

大体上：它应该是用的 freeList  ，把内存按照固定大小，进行分配。

内存碎片量应该不会太大，线程间锁的竞争也不会太大。

